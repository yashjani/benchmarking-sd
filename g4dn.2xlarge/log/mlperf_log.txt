:::MLLOG {"namespace": "", "time_ms": 1717727433168, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727436126, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.9574134349823}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727436206, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A beautiful landscape with mountains and rivers", "count": 1}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727467100, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.89582872390747, "gpu_metrics": [{"gpu_utilization": "38", "gpu_memory_utilization": "14", "gpu_memory_total": "15360", "gpu_memory_used": "4521", "gpu_memory_free": "10580", "gpu_temperature": "41", "gpu_power_draw": "33.26"}], "ondemand_cost": 0.00645379533343845, "reserved_one_year_cost": 0.00406795078198115, "reserved_three_year_cost": 0.0027892067597972024, "spot_cost": 0.002747154104034106, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727467101, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.71985650062561}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727467365, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727470133, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.7669949531555176}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727470221, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A futuristic cityscape at night", "count": 2}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727500396, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.17857599258423, "gpu_metrics": [{"gpu_utilization": "20", "gpu_memory_utilization": "10", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "46", "gpu_power_draw": "34.32"}], "ondemand_cost": 0.006303969207339816, "reserved_one_year_cost": 0.003973512505690256, "reserved_three_year_cost": 0.002724454777108298, "spot_cost": 0.0026833783820072806, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727500397, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.019444465637207}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727500663, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727503288, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6243343353271484}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727503379, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A serene beach with crystal clear water", "count": 3}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727533627, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.25198245048523, "gpu_metrics": [{"gpu_utilization": "7", "gpu_memory_utilization": "5", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "48", "gpu_power_draw": "34.69"}], "ondemand_cost": 0.0063193030007680255, "reserved_one_year_cost": 0.003983177689313888, "reserved_three_year_cost": 0.0027310817490021387, "spot_cost": 0.0026899054395556447, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727533629, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.04671287536621}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727533895, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727536509, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6133992671966553}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727536598, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A majestic forest in autumn", "count": 4}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727566912, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.316407680511475, "gpu_metrics": [{"gpu_utilization": "71", "gpu_memory_utilization": "22", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "49", "gpu_power_draw": "35.02"}], "ondemand_cost": 0.006332760715484619, "reserved_one_year_cost": 0.003991660344600678, "reserved_three_year_cost": 0.0027368979156017306, "spot_cost": 0.002695633916258812, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727566914, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.169770002365112}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727567178, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727569774, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.5958986282348633}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727569864, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A vibrant market street in a foreign country", "count": 5}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727600250, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.388407468795776, "gpu_metrics": [{"gpu_utilization": "30", "gpu_memory_utilization": "11", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "49", "gpu_power_draw": "35.08"}], "ondemand_cost": 0.0063478006712595625, "reserved_one_year_cost": 0.004001140316724778, "reserved_three_year_cost": 0.002743397896488508, "spot_cost": 0.002702035897433758, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727600251, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.231215476989746}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727600518, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727603133, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.613410472869873}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727603223, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A sci-fi spaceship exploring a distant galaxy", "count": 6}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727633721, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.501545429229736, "gpu_metrics": [{"gpu_utilization": "60", "gpu_memory_utilization": "19", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.30"}], "ondemand_cost": 0.006371433934105767, "reserved_one_year_cost": 0.004016036814848582, "reserved_three_year_cost": 0.0027536117401387957, "spot_cost": 0.0027120957477490106, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727633723, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.327171325683594}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727633991, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727636599, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.60709285736084}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727636690, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A mystical castle surrounded by clouds", "count": 7}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727667209, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.522021770477295, "gpu_metrics": [{"gpu_utilization": "6", "gpu_memory_utilization": "4", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.10"}], "ondemand_cost": 0.006375711214277479, "reserved_one_year_cost": 0.004018732866446177, "reserved_three_year_cost": 0.0027554602987236447, "spot_cost": 0.0027139164357582726, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727667210, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.33291006088257}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727667478, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727670120, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.640700578689575}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727670211, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A cute puppy playing in the park", "count": 8}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727700779, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.571537971496582, "gpu_metrics": [{"gpu_utilization": "80", "gpu_memory_utilization": "22", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.30"}], "ondemand_cost": 0.006386054598490397, "reserved_one_year_cost": 0.004025252499580383, "reserved_three_year_cost": 0.0027599305113156637, "spot_cost": 0.0027183192512989043, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727700781, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.388099431991577}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727701044, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727703666, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6207170486450195}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727703758, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A bustling city street at rush hour", "count": 9}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727734278, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.52487587928772, "gpu_metrics": [{"gpu_utilization": "30", "gpu_memory_utilization": "11", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.49"}], "ondemand_cost": 0.006376307405895658, "reserved_one_year_cost": 0.004019108657439549, "reserved_three_year_cost": 0.002755717961324586, "spot_cost": 0.0027141702136, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727734279, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.351781368255615}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727734549, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727737195, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6458046436309814}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727737286, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A tranquil Japanese garden with cherry blossoms", "count": 10}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727767763, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.480014324188232, "gpu_metrics": [{"gpu_utilization": "80", "gpu_memory_utilization": "22", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.40"}], "ondemand_cost": 0.006366936325497097, "reserved_one_year_cost": 0.0040132018860181175, "reserved_three_year_cost": 0.002751667959822549, "spot_cost": 0.00271018127365907, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727767764, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.32219696044922}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727768028, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727770642, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.612722158432007}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727770733, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A sunset over the ocean with sailboats", "count": 11}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727801285, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.55570888519287, "gpu_metrics": [{"gpu_utilization": "26", "gpu_memory_utilization": "10", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.47"}], "ondemand_cost": 0.006382748078240289, "reserved_one_year_cost": 0.004023168336550395, "reserved_three_year_cost": 0.002758501496579912, "spot_cost": 0.0027169117817083996, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727801286, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.374194860458374}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727801555, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727804198, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6424803733825684}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727804289, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A magical forest with glowing plants", "count": 12}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727834811, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.526316165924072, "gpu_metrics": [{"gpu_utilization": "7", "gpu_memory_utilization": "5", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.38"}], "ondemand_cost": 0.006376608265770806, "reserved_one_year_cost": 0.004019298295180002, "reserved_three_year_cost": 0.0027558479872014786, "spot_cost": 0.0027142982790867485, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727834813, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.377673625946045}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727835077, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727837685, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6067581176757812}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727837776, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A dragon flying over a medieval town", "count": 13}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727868262, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.489758014678955, "gpu_metrics": [{"gpu_utilization": "22", "gpu_memory_utilization": "10", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "51", "gpu_power_draw": "35.30"}], "ondemand_cost": 0.006368971674177382, "reserved_one_year_cost": 0.004014484805266063, "reserved_three_year_cost": 0.002752547598547406, "spot_cost": 0.002711047650138537, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727868264, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.33828592300415}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727868531, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727871147, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6157939434051514}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727871238, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A bustling market in an ancient city", "count": 14}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727901741, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.50587511062622, "gpu_metrics": [{"gpu_utilization": "58", "gpu_memory_utilization": "19", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.47"}], "ondemand_cost": 0.006372338356441921, "reserved_one_year_cost": 0.0040166068895657854, "reserved_three_year_cost": 0.002754002614153756, "spot_cost": 0.0027124807285865147, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727901743, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.34597420692444}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727902007, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727904604, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.596362829208374}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727904695, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A spaceship landing on an alien planet", "count": 15}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727935286, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.594150066375732, "gpu_metrics": [{"gpu_utilization": "7", "gpu_memory_utilization": "5", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.61"}], "ondemand_cost": 0.006390778013865153, "reserved_one_year_cost": 0.004028229758739471, "reserved_three_year_cost": 0.0027619718809922538, "spot_cost": 0.0027203298434019087, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727935287, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.399393796920776}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727935556, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727938179, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.622593879699707}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727938270, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A portrait of a futuristic cyborg", "count": 16}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717727968844, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.57663655281067, "gpu_metrics": [{"gpu_utilization": "0", "gpu_memory_utilization": "0", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.53"}], "ondemand_cost": 0.006387119635476006, "reserved_one_year_cost": 0.004025923812786738, "reserved_three_year_cost": 0.0027603907999065188, "spot_cost": 0.002718772600154082, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717727968845, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.365184783935547}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717727969113, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717727971736, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.622225761413574}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717727971829, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A fantasy warrior in shining armor", "count": 17}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728002271, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.446383237838745, "gpu_metrics": [{"gpu_utilization": "40", "gpu_memory_utilization": "14", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "51", "gpu_power_draw": "35.49"}], "ondemand_cost": 0.006359911165237426, "reserved_one_year_cost": 0.004008773792982101, "reserved_three_year_cost": 0.0027486318200826646, "spot_cost": 0.002707190909564495, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728002272, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.348034858703613}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717728002539, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717728005301, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.76090145111084}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717728005393, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A peaceful village in the mountains", "count": 18}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728035977, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.58778214454651, "gpu_metrics": [{"gpu_utilization": "64", "gpu_memory_utilization": "19", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.30"}], "ondemand_cost": 0.0063894478257497155, "reserved_one_year_cost": 0.0040273913156986235, "reserved_three_year_cost": 0.002761396999160449, "spot_cost": 0.0027197636290192603, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728035978, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.43328547477722}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717728036247, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717728038853, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6059036254882812}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717728038944, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A steampunk city with flying machines", "count": 19}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728069497, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.555212020874023, "gpu_metrics": [{"gpu_utilization": "7", "gpu_memory_utilization": "5", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.49"}], "ondemand_cost": 0.006382644288804796, "reserved_one_year_cost": 0.004023102916081746, "reserved_three_year_cost": 0.002758456640773349, "spot_cost": 0.0027168676021893817, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728069498, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.37639880180359}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717728069767, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717728072369, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6020374298095703}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717728072458, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A cozy cottage in a snowy forest", "count": 20}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728103031, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.574995756149292, "gpu_metrics": [{"gpu_utilization": "70", "gpu_memory_utilization": "21", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.38"}], "ondemand_cost": 0.006386776891284519, "reserved_one_year_cost": 0.004025707774559657, "reserved_three_year_cost": 0.0027602426724301445, "spot_cost": 0.0027186267059842745, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728103032, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.404918909072876}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717728103299, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717728105957, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6574504375457764}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717728106050, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A vast desert with towering sand dunes", "count": 21}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728136672, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.627360582351685, "gpu_metrics": [{"gpu_utilization": "59", "gpu_memory_utilization": "19", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.59"}], "ondemand_cost": 0.006397715321646796, "reserved_one_year_cost": 0.004032602476676305, "reserved_three_year_cost": 0.002764970052573416, "spot_cost": 0.0027232828117807703, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728136673, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.409415245056152}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717728136943, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717728139565, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6216623783111572}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717728139657, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A lively street fair with colorful stalls", "count": 22}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728170196, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.542211532592773, "gpu_metrics": [{"gpu_utilization": "55", "gpu_memory_utilization": "19", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.44"}], "ondemand_cost": 0.006379928631252713, "reserved_one_year_cost": 0.004021391185124715, "reserved_three_year_cost": 0.0027572829855812926, "spot_cost": 0.002715711642106374, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728170197, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.389583587646484}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717728170463, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717728173071, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6079673767089844}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717728173160, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A knight fighting a dragon in a fiery battle", "count": 23}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728203772, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.613744258880615, "gpu_metrics": [{"gpu_utilization": "18", "gpu_memory_utilization": "10", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.53"}], "ondemand_cost": 0.006394871022966172, "reserved_one_year_cost": 0.004030809660752614, "reserved_three_year_cost": 0.0027637408011489443, "spot_cost": 0.0027220720936854677, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728203773, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.42345690727234}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717728204036, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717728206656, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6189165115356445}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717728206747, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A serene lake surrounded by autumn trees", "count": 24}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728237282, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.537786960601807, "gpu_metrics": [{"gpu_utilization": "85", "gpu_memory_utilization": "23", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.22"}], "ondemand_cost": 0.00637900438732571, "reserved_one_year_cost": 0.004020808616479237, "reserved_three_year_cost": 0.0027568835450543297, "spot_cost": 0.0027153182239135105, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728237283, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.380386352539062}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717728237552, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717728240172, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6192076206207275}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717728240263, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A futuristic train traveling through a neon-lit city", "count": 25}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728270862, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.60189914703369, "gpu_metrics": [{"gpu_utilization": "57", "gpu_memory_utilization": "19", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.65"}], "ondemand_cost": 0.006392396710713705, "reserved_one_year_cost": 0.004029250054359436, "reserved_three_year_cost": 0.0027626714507738752, "spot_cost": 0.002721018865823746, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728270863, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.416019439697266}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717728271132, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717728273784, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6508712768554688}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717728273876, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A mysterious forest with hidden treasures", "count": 26}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728304504, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.63110065460205, "gpu_metrics": [{"gpu_utilization": "80", "gpu_memory_utilization": "22", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.28"}], "ondemand_cost": 0.00639849658118354, "reserved_one_year_cost": 0.004033094919522603, "reserved_three_year_cost": 0.0027653076979849076, "spot_cost": 0.0027236153665383656, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728304506, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.452482223510742}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717728304774, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717728307381, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6064860820770264}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717728307472, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A majestic eagle soaring over the Grand Canyon", "count": 27}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728338052, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.581718921661377, "gpu_metrics": [{"gpu_utilization": "55", "gpu_memory_utilization": "19", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.30"}], "ondemand_cost": 0.006388181285858155, "reserved_one_year_cost": 0.004026592991352082, "reserved_three_year_cost": 0.002760849624872208, "spot_cost": 0.002719224507451058, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728338053, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.41643714904785}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717728338323, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717728340946, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.623033046722412}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717728341038, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A charming small town during Christmas", "count": 28}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728371624, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.589064836502075, "gpu_metrics": [{"gpu_utilization": "43", "gpu_memory_utilization": "15", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.32"}], "ondemand_cost": 0.0063897157658471, "reserved_one_year_cost": 0.004027560203472773, "reserved_three_year_cost": 0.0027615127977397703, "spot_cost": 0.0027198776817123093, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728371625, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.425169467926025}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717728371888, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717728374496, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6064703464508057}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717728374588, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A sci-fi laboratory with advanced technology", "count": 29}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728405159, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.574405431747437, "gpu_metrics": [{"gpu_utilization": "0", "gpu_memory_utilization": "0", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.57"}], "ondemand_cost": 0.006386653579076132, "reserved_one_year_cost": 0.0040256300485134126, "reserved_three_year_cost": 0.002760189379254977, "spot_cost": 0.0027185742163062096, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728405160, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.36674928665161}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1717728405429, "event_type": "INTERVAL_START", "key": "model_loading", "value": {"model": "CompVis/stable-diffusion-v1-4"}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 102}}
:::MLLOG {"namespace": "", "time_ms": 1717728408039, "event_type": "INTERVAL_END", "key": "model_loading", "value": {"duration": 2.6092097759246826}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1717728408131, "event_type": "INTERVAL_START", "key": "image_generation", "value": {"model": "CompVis/stable-diffusion-v1-4", "prompt": "A vibrant coral reef teeming with sea life", "count": 30}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1717728438670, "event_type": "INTERVAL_END", "key": "image_generation", "value": {"duration": 30.54191541671753, "gpu_metrics": [{"gpu_utilization": "50", "gpu_memory_utilization": "15", "gpu_memory_total": "15360", "gpu_memory_used": "3963", "gpu_memory_free": "11138", "gpu_temperature": "50", "gpu_power_draw": "35.49"}], "ondemand_cost": 0.006379866775936551, "reserved_one_year_cost": 0.004021352196534475, "reserved_three_year_cost": 0.0027572562528981105, "spot_cost": 0.0027156853124698003, "image_size": [512, 512]}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1717728438671, "event_type": "INTERVAL_END", "key": "inference_latency", "value": {"duration": 30.368614196777344}, "metadata": {"file": "/home/ubuntu/benchmark/benchmark.py", "lineno": 143}}
